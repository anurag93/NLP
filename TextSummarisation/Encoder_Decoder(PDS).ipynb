{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Encoder_Decoder(PDS).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5rWgQA2LD2sr","colab_type":"code","outputId":"b7fba3b3-928d-472f-cd99-1f3f4485ff8b","executionInfo":{"status":"ok","timestamp":1564069003103,"user_tz":-330,"elapsed":2250,"user":{"displayName":"Anurag Sengupta","photoUrl":"https://lh6.googleusercontent.com/-bHfaElQpxYo/AAAAAAAAAAI/AAAAAAAAAfQ/hkXJqx23O68/s64/photo.jpg","userId":"07433667428799863840"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from random import randint\n","from numpy import array\n","from numpy import argmax\n","from numpy import array_equal\n","from keras.utils import to_categorical\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.layers import concatenate\n","import numpy as np\n","from keras.callbacks import EarlyStopping\n","from keras.utils.vis_utils import plot_model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7s5krDAPEP71","colab_type":"code","colab":{}},"source":["def generate_sequence(length, n_unique):\n","\treturn [randint(1, n_unique-1) for _ in range(length)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"42hhbAJREyXX","colab_type":"code","colab":{}},"source":["def get_dataset(n_in, n_out, cardinality, n_samples):\n","        X1, X2, y = list(), list(), list()\n","        for _ in range(n_samples):\n","            # generate source sequence\n","            source = generate_sequence(n_in, (cardinality-1)/2)\n","            # define padded target sequence\n","            rev = source[:n_out]\n","            rev.reverse()\n","            target = [r for r in rev]\n","            target.extend(2*r for r in source[:n_out])\n","            # create padded input target sequence\n","            target_in = [0] + target[:2]\n","            target_in.extend([0]+target[3:5])\n","            # encode\n","            src_encoded = to_categorical([source], num_classes=cardinality)\n","            tar_encoded = to_categorical([target], num_classes=cardinality)\n","            tar2_encoded = to_categorical([target_in], num_classes=cardinality)\n","            # store\n","            X1.append(src_encoded)\n","            X2.append(tar2_encoded)\n","            y.append(tar_encoded)\n","        X1 = np.squeeze(array(X1), axis=1) \n","        X2 = np.squeeze(array(X2), axis=1) \n","        y = np.squeeze(array(y), axis=1) \n","        return array(X1), array(X2), array(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RemMXJchE1i6","colab_type":"code","colab":{}},"source":["def define_models(n_input, n_output, n_units):\n","        # define training encoder for reverse\n","        encoder_inputs = Input(shape=(None, n_input))\n","        encoder = LSTM(n_units, return_state=True)\n","        encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","        encoder_states = [state_h, state_c]\n","  \n","\n","        # define training decoder for reverse\n","        decoder_inputs_rev = Input(shape=(None, n_output))\n","        decoder_lstm_rev = LSTM(n_units, return_sequences=True, return_state=True)\n","        decoder_outputs_rev, _, _ = decoder_lstm_rev(decoder_inputs_rev, initial_state=encoder_states)\n","        decoder_dense_rev = Dense(n_output, activation='softmax')\n","        decoder_outputs_rev = decoder_dense_rev(decoder_outputs_rev)\n","\n","        # define the traning decoder for multiply\n","        decoder_inputs_mult = Input(shape=(None, n_output))\n","        decoder_lstm_mult = LSTM(n_units, return_sequences=True, return_state=True)\n","        decoder_outputs_mult, _, _ = decoder_lstm_mult(decoder_inputs_mult, initial_state=encoder_states)\n","        decoder_dense_mult= Dense(n_output, activation='softmax')\n","        decoder_outputs_mult = decoder_dense_mult(decoder_outputs_mult)\n","\n","\n","        model = Model([encoder_inputs, decoder_inputs_rev, decoder_inputs_mult], [decoder_outputs_rev, decoder_outputs_mult])\n","        # define training decoder for multiply\n","\n","        # define inference encoder\n","        encoder_model = Model(encoder_inputs, encoder_states)\n","        # define inference decoder reverse\n","        decoder_state_input_h_rev = Input(shape=(n_units,))\n","        decoder_state_input_c_rev = Input(shape=(n_units,))\n","        decoder_states_inputs_rev = [decoder_state_input_h_rev, decoder_state_input_c_rev]\n","        decoder_outputs_rev, state_h_rev, state_c_rev = decoder_lstm_rev(decoder_inputs_rev, initial_state=decoder_states_inputs_rev)\n","        decoder_states_rev = [state_h_rev, state_c_rev]\n","        decoder_outputs_rev = decoder_dense_rev(decoder_outputs_rev)\n","        decoder_model_rev = Model([decoder_inputs_rev] + decoder_states_inputs_rev, [decoder_outputs_rev] + decoder_states_rev)\n","\n","        # define inference decoder mult\n","        decoder_state_input_h_mult = Input(shape=(n_units,))\n","        decoder_state_input_c_mult = Input(shape=(n_units,))\n","        decoder_states_inputs_mult = [decoder_state_input_h_mult, decoder_state_input_c_mult]\n","        decoder_outputs_mult, state_h_mult, state_c_mult = decoder_lstm_mult(decoder_inputs_mult, initial_state=decoder_states_inputs_mult)\n","        decoder_states_mult = [state_h_mult, state_c_mult]\n","        decoder_outputs_mult = decoder_dense_mult(decoder_outputs_mult)\n","        decoder_model_mult = Model([decoder_inputs_mult] + decoder_states_inputs_mult, [decoder_outputs_mult] + decoder_states_mult)\n","        # return all models\n","        return model, encoder_model, decoder_model_rev, decoder_model_mult"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OIDxHZyNE42N","colab_type":"code","colab":{}},"source":["# generate target given source sequence\n","def predict_sequence(infenc, infdec_rev, infdec_mult, source, n_steps, cardinality):\n","        # encode\n","        state = infenc.predict(source)\n","        # start of sequence input\n","        target_seq_rev = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n","        target_seq_mult = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n","        # collect predictions\n","        output = list()\n","        for t in range(3):\n","            # predict next char\n","            yhat_rev, h_rev, c_rev = infdec_rev.predict([target_seq_rev] + state)\n","            # store prediction\n","            output.appensd(yhat_rev[0,0,:])\n","            # update state\n","            state = [h_rev, c_rev]\n","            # update target sequence\n","            target_seq_rev = yhat_rev\n","        state = infenc.predict(source)\n","        for t in range(3):\n","            # predict next char\n","            yhat_mult, h_mult, c_mult = infdec_mult.predict([target_seq_mult] + state)\n","            # store prediction\n","            output.append(yhat_mult[0,0,:])\n","            # update state\n","            state = [h_mult, c_mult]\n","            # update target sequence\n","            target_seq_mult = yhat_mult\n","        return array(output)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_J1HnBNBE-pS","colab_type":"code","colab":{}},"source":["# decode a one hot encoded string\n","def one_hot_decode(encoded_seq):\n","\treturn [argmax(vector) for vector in encoded_seq]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"05X1NVeQFLuE","colab_type":"code","outputId":"e1212734-fd9a-4e35-a367-8e69daeeaf01","executionInfo":{"status":"ok","timestamp":1564069389490,"user_tz":-330,"elapsed":388617,"user":{"displayName":"Anurag Sengupta","photoUrl":"https://lh6.googleusercontent.com/-bHfaElQpxYo/AAAAAAAAAAI/AAAAAAAAAfQ/hkXJqx23O68/s64/photo.jpg","userId":"07433667428799863840"}},"colab":{"base_uri":"https://localhost:8080/","height":547}},"source":["# configure problem\n","n_features = 50 + 1\n","n_steps_in = 6\n","n_steps_out = 3\n","# define model\n","train, infenc, infdec_rev, infdec_mult = define_models(n_features, n_features, 128)\n","train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n","# generate training dataset\n","X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 100000)\n","print(X1.shape,X2.shape,y.shape)\n","# train model\n","earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n","train.fit([X1, X2[:, :3, :], X2[:, 3:, :]], [y[:, :3, :],y[:, 3:, :]], epochs=5, verbose = 1, callbacks=[earlystop])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0725 15:36:42.594272 140439306545024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0725 15:36:42.632059 140439306545024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0725 15:36:42.639251 140439306545024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0725 15:36:43.570635 140439306545024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0725 15:36:43.595568 140439306545024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["(100000, 6, 51) (100000, 6, 51) (100000, 6, 51)\n"],"name":"stdout"},{"output_type":"stream","text":["W0725 15:36:48.607455 140439306545024 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0725 15:36:50.392460 140439306545024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/5\n","100000/100000 [==============================] - 80s 796us/step - loss: 0.9095 - dense_1_loss: 0.5088 - dense_2_loss: 0.4008 - dense_1_acc: 0.8266 - dense_2_acc: 0.8827\n","Epoch 2/5\n","   224/100000 [..............................] - ETA: 1:16 - loss: 0.0358 - dense_1_loss: 0.0266 - dense_2_loss: 0.0093 - dense_1_acc: 0.9940 - dense_2_acc: 1.0000"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,dense_1_loss,dense_2_loss,dense_1_acc,dense_2_acc\n","  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"],"name":"stderr"},{"output_type":"stream","text":["100000/100000 [==============================] - 75s 746us/step - loss: 0.0160 - dense_1_loss: 0.0102 - dense_2_loss: 0.0059 - dense_1_acc: 0.9987 - dense_2_acc: 0.9995\n","Epoch 3/5\n","100000/100000 [==============================] - 75s 748us/step - loss: 0.0065 - dense_1_loss: 0.0038 - dense_2_loss: 0.0027 - dense_1_acc: 0.9993 - dense_2_acc: 0.9996\n","Epoch 4/5\n","100000/100000 [==============================] - 75s 746us/step - loss: 0.0053 - dense_1_loss: 0.0026 - dense_2_loss: 0.0027 - dense_1_acc: 0.9994 - dense_2_acc: 0.9993\n","Epoch 5/5\n","100000/100000 [==============================] - 75s 746us/step - loss: 0.0020 - dense_1_loss: 0.0012 - dense_2_loss: 7.3810e-04 - dense_1_acc: 0.9998 - dense_2_acc: 0.9999\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fba6fd427b8>"]},"metadata":{"tags":[]},"execution_count":7}]}]}